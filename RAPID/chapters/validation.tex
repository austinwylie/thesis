\chapter{Validation}
\label{validation}
In this last chapter, we summarize our validation of RAPID, showing that the system meets Chapter~\ref{requirements}'s critical requirements, correctly uses the concepts and technologies outlined in our Background, and is efficient enough for real use in the future.

We made two primary contributions: 1) guidelines and findings for API developers---at this point, Francis---validating our data model and overall system design and 2) performance testing results for common operations.

\section{Functionality}
RAPID includes a geospatial data model as well as file parsing and querying capabilities. We must, therefore, verify that RAPID's design meets its specification and that our codebase parses, stores, queries, and outputs geospatial data correctly. These are particularly prudent, as RAPID's entire purpose is to enable portability and interchangeability for \textit{external} partners and \textit{future} developers.

Our example setup between ABC Pipeline Co. and XYZ Operations is a relatively complete case study, showing real class instances and relationships. By showing the models and implementation patterns in Chapter~\ref{design} that support that needed functionality, it should be apparent that RAPID completely and successfully meets our system requirements from Chapter~\ref{requirements}.

Even though our model is, hopefully, convincing on its own, we worked with another student developer, Kishan Patel, to integrate a web application with RAPID for further validation. We call this software \textit{RAPID UI}, which visualizes spatial entities and our organization of data (Features in DataLayers, DataLayers grouped into GeoViews).

Our peer developer, Patel, had to become acquainted with basic geospatial concepts and client-side libraries, but our contributions to RAPID were significant and successful enough that he was able to create a sensible UI using our most important API calls. Second, being able to visualize our data---both geographic geometries and accompanying properties---we literally see that data makes it through RAPID, from beginning to end, as expected. As an additional nicety, we share and visualize several datasets with RAPID UI that were recently recommended by pipeline operating partners.

Francis describes our work with Patel in-depth---she worked with him to design and fully test REST calls---but please see the short following summary, which outlines our expectations and findings for RAPID UI (focusing on the data model's role)~\cite{Francis}.

\begin{itemize}
\item A primary goal in researching GIS standards and technologies was to ensure RAPID operates as expected when handling (rather finicky) geospatial data. Therefore, we set up several sample DataLayers (from GeoJSON and Shapefiles) for RAPID UI to attempt retrieving and visualizing. In particular, we had the goal of requiring as little custom UI logic as possible---relying instead upon pre-built GIS tools.

Patel and Francis ensured RAPID UI could properly request data and handle GeoJSON responses through the API (using common HTTP libraries in Python and JavaScript). After RAPID UI fetches standardized files, using particular geospatial libraries \textit{should and does} let the application parse and visualize our data in one step.

\textit{[Add screenshot.]}

\item Aside from visualizing correctly-shaped and -placed geospatial Features, we had to count on RAPID UI retrieving and displaying relationships between GeoViews, DataLayers, and Features. Patel, using RAPID's JSON responses (designed by Francis), displays available GeoViews in RAPID UI, letting users switch between them and their DataLayers. That is, users can observe and analyze whichever datasets they need at that time.

\item Last, RAPID UI incorporates RAPID's geospatiotemporality by filtering data by time. For example, users can switch between days of a single month to see which Features are generated or applicable on which days.

This characteristic is demonstrably useful: out-of-date Features can be imported alongside recent data that is of much more interest. Operators frequently value hazard and encroachment \textit{prevention}, using the most up-to-date information~\cite{Dunning2013}.
\end{itemize}

\section{Performance}
The previous section shows that, given our data model and business logic, RAPID operates properly; we now use this section to highlight our core data model's performance, showing that it is an efficient base for future additions. We point out specific interface actions that typify DSS work and compare their runtimes.

\subsection{Setup}
\textit{[Finish this section. Use three dataset sizes for Features: small (tens), medium (thousands), large (hundred-thousands). Test both Points and Polygons (significantly different complexities for spatial operators). Also check performance for directly retrieving a GeoView and its DataLayers.]}\footnote{Performance testing spatial schemas and source code could be a thesis to itself. Here, we cast a wide net, but still tackle our most visible and potentially-taxing operations.}

% small, medium, large
% points, polygons
% Specific features
% DataLayer lookup
% GeoView lookup

\subsection{Results}
\textit{[Finish this section.]}

\section{Unit testing discussion}
The following recommendations could be used to further validate RAPID with a thorough unit test suite.\footnote{On the back end, RAPID could use the Python's built-in testing module, \texttt{unittest}~\cite{DjangoTesting}} Once each required field for geospatial features is located for each possible input and output, exhaustive unit tests can ensure that fields in an input format can be converted to the corresponding fields in any output format. In the event storage or conversion fails, unit tests for the following components would reveal where and why:

\begin{itemize}
\item Writable and parseable digital format like GeoJSON or Shapefile.
\item In-memory objects (our own models or GEOSGeometry objects\footnote{We discussed GEOSGeometry briefly in Section~\ref{sec:export}.}).
\item WKT or GeoJSON---abstract text formats for geospatial features.
\item Abstract data persisted in PostGIS.
\end{itemize}

Data can move up and down that list; each step and transition (all outlined in Chapter~\ref{design}), should be considered a data integrity checkpoint that deserves a unit test. For instance, a Polygon made up of coordinate pairs (0, 0), (0, 10), and (10, 0) still needs to have the same meaning---a triangle with those three points---no matter its format or original location.

GeoJSON, Shapefiles, Python objects, WKT, and PostGIS data structures can all be inspected to see that the same data is contained in each. If not, it was misshaped somewhere along the line---traceable with these ``checkpoints.''